name: CKAN DataPusher Plus Single File Test
on:
  workflow_dispatch:
# Workflow-level defaults
env:
  CKAN_VERSION: "2.11"
  POSTGRES_PASSWORD: postgres
  CKAN_DB_PASSWORD: pass
  CKAN_SITE_URL: http://localhost:5000
  CKAN_SITE_ID: default
  CKAN_SITE_TITLE: "CKAN Test Instance"
jobs:
  setup:
    runs-on: ubuntu-latest
    container:
      image: ckan/ckan-dev:2.11
      options: --user root
    services:
      solr:
        image: ckan/ckan-solr:2.11-solr9
        ports: ["8983:8983"]
      postgres:
        image: ckan/ckan-postgres-dev:2.11
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
      redis:
        image: redis:3
        ports: ["6379:6379"]
    # Job-specific environment (these will be available inside the container)
    env:
      CKAN_SQLALCHEMY_URL: postgresql://ckan_default:pass@postgres/ckan_test
      CKAN_DATASTORE_WRITE_URL: postgresql://datastore_write:pass@postgres/datastore_test
      CKAN_DATASTORE_READ_URL: postgresql://datastore_read:pass@postgres/datastore_test
      CKAN_SOLR_URL: http://solr:8983/solr/ckan
      CKAN_REDIS_URL: redis://redis:6379/1
      CKAN_SITE_URL: http://localhost:5000
    steps:
      - name: Fix permissions and install essential tools
        run: |
          mkdir -p /__w/_temp
          chmod -R 777 /__w/_temp  
          chmod -R 777 /__w/  
          apt-get update -y
          apt-get install -y curl wget net-tools procps postgresql-client jq  
          echo "Essential tools installed successfully"
      - uses: actions/checkout@v4
      - name: Wait for PostgreSQL to be ready
        run: |
          echo "Waiting for PostgreSQL to be ready..."
          timeout=90
          while [ $timeout -gt 0 ]; do
            if PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "SELECT 1;" >/dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              break
            fi
            echo "Postgres not ready yet ($timeout s left)..."
            sleep 3
            timeout=$((timeout-3))
          done
          if [ $timeout -le 0 ]; then
            echo "Timeout waiting for PostgreSQL"
            exit 1
          fi
      - name: Setup database users and permissions
        run: |
          set -eu 
          echo "Creating database users (if not exist)..."
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -Atc "SELECT 1 FROM pg_roles WHERE rolname='ckan_default'" | grep -q 1 || \
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE USER ckan_default WITH PASSWORD '$CKAN_DB_PASSWORD';"
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -Atc "SELECT 1 FROM pg_roles WHERE rolname='datastore_write'" | grep -q 1 || \
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE USER datastore_write WITH PASSWORD '$CKAN_DB_PASSWORD';"
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -Atc "SELECT 1 FROM pg_roles WHERE rolname='datastore_read'" | grep -q 1 || \
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE USER datastore_read WITH PASSWORD '$CKAN_DB_PASSWORD';"
          echo "Creating databases (if not exist)..."
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -Atc "SELECT 1 FROM pg_database WHERE datname='ckan_test'" | grep -q 1 || \
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE DATABASE ckan_test OWNER ckan_default;"
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -Atc "SELECT 1 FROM pg_database WHERE datname='datastore_test'" | grep -q 1 || \
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE DATABASE datastore_test OWNER ckan_default;"
          echo "Granting permissions (best-effort)..."
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE ckan_test TO ckan_default;"  
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE datastore_test TO datastore_write;"  
          PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "GRANT CONNECT ON DATABASE datastore_test TO datastore_read;"  
          echo "Database setup completed"
      - name: Install requirements, ckanapi and datapusher-plus
        run: |
          set -eu
          # Use pip from the container (image usually has Python/pip)
          python3 -m pip install --upgrade pip setuptools wheel  
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt  
          fi
          if [ -f requirements-dev.txt ]; then
            pip install -r requirements-dev.txt  
          fi
          # install current repo editable if present
          if [ -f setup.py ] || [ -f pyproject.toml ]; then
            pip install -e .  
          fi
          # Ensure ckanapi and datapusher-plus are available
          pip install --upgrade ckanapi  
          apt install -y python3-virtualenv python3-dev python3-pip python3-wheel build-essential libxslt1-dev libxml2-dev zlib1g-dev git libffi-dev libpq-dev uchardet unzip  
          # Install datapusher-plus package (the pip package name is typically datapusher-plus)
          pip install -e 'git+https://github.com/dathere/datapusher-plus.git#egg=datapusher-plus'  
          pip install -e 'git+https://github.com/ckan/ckanext-scheming.git#egg=ckanext-scheming'  
          echo "Installed ckanapi and datapusher-plus (best-effort)"
      - name: Install qsv (musl static)
        run: |
          set -eu
          echo "Attempting to download static qsv musl binary (best-effort)..."
          QSV_VER="4.0.0"
          QSV_ZIP="qsv-${QSV_VER}-x86_64-unknown-linux-musl.zip"
          QSV_URL="https://github.com/dathere/qsv/releases/download/${QSV_VER}/${QSV_ZIP}"
          mkdir -p /tmp/qsv && cd /tmp/qsv  
          if wget -q --spider "$QSV_URL"; then
            wget -q "$QSV_URL" -O "$QSV_ZIP"  
            unzip -o "$QSV_ZIP"  
            # try to find 'qsv' or 'qsvdp' binary
            if [ -f qsvdp ]; then
              mv qsvdp /usr/local/bin/qsvdp  
              chmod +x /usr/local/bin/qsvdp  
              echo "Installed qsvdp to /usr/local/bin/qsvdp"
            elif [ -f qsv ]; then
              mv qsv /usr/local/bin/qsv  
              chmod +x /usr/local/bin/qsv  
              echo "Installed qsv to /usr/local/bin/qsv"
            else
              echo "Downloaded archive but could not find qsv binary inside"
            fi
          else
            echo "qsv release URL not reachable; skipping qsv install"
          fi
          /usr/local/bin/qsvdp --version >/dev/null 2>&1 || /usr/local/bin/qsv --version >/dev/null 2>&1 || echo "qsv not installed or not runnable (this is okay for plugin presence test)."
      
      - name: Setup CKAN configuration (/srv/app/src/ckan/test-core.ini)
        run: |
          set -eu
          # Defensive URL substitutions (keep these)
          sed -i "s|^sqlalchemy.url.*|sqlalchemy.url = ${CKAN_SQLALCHEMY_URL:-***postgres/ckan_test}|g" /srv/app/src/ckan/test-core.ini  
          sed -i "s|^ckan.datastore.write_url.*|ckan.datastore.write_url = ${CKAN_DATASTORE_WRITE_URL:-***postgres/datastore_test}|g" /srv/app/src/ckan/test-core.ini  
          sed -i "s|^ckan.datastore.read_url.*|ckan.datastore.read_url = ${CKAN_DATASTORE_READ_URL:-***postgres/datastore_test}|g" /srv/app/src/ckan/test-core.ini  
          if ! grep -q "^solr_url" /srv/app/src/ckan/test-core.ini; then
            echo "solr_url = ${CKAN_SOLR_URL:-http://solr:8983/solr/ckan}" >> /srv/app/src/ckan/test-core.ini
          fi
          if ! grep -q "^ckan.redis.url" /srv/app/src/ckan/test-core.ini; then
            echo "ckan.redis.url = ${CKAN_REDIS_URL:-redis://redis:6379/1}" >> /srv/app/src/ckan/test-core.ini
          fi
          # Desired values (use env vars when present, otherwise fall back)
          CKAN_SITE_URL="${CKAN_SITE_URL:-http://localhost:5000}"
          CKAN_SQLALCHEMY_URL="${CKAN_SQLALCHEMY_URL:-***postgres/ckan_test}"
          CKAN_DATASTORE_WRITE_URL="${CKAN_DATASTORE_WRITE_URL:-***postgres/datastore_test}"
          CKAN_DATASTORE_READ_URL="${CKAN_DATASTORE_READ_URL:-***postgres/datastore_test}"
          CKAN_SOLR_URL="${CKAN_SOLR_URL:-http://solr:8983/solr/ckan}"
          CKAN_REDIS_URL="${CKAN_REDIS_URL:-redis://redis:6379/1}"
          # create temp files to hold lists (POSIX sh-safe)
          REPLACE_FILE="$(mktemp)"
          ADD_FILE="$(mktemp)"
          MISSING_ADD_FILE="$(mktemp)"
          : > "$REPLACE_FILE"
          : > "$ADD_FILE"
          : > "$MISSING_ADD_FILE"
          # REPLACE_ENTRIES (key|value) - write expanded lines to REPLACE_FILE
          printf '%s\n' \
            "ckan.site_url|${CKAN_SITE_URL}" \
            "sqlalchemy.url|${CKAN_SQLALCHEMY_URL}" \
            "ckan.datastore.write_url|${CKAN_DATASTORE_WRITE_URL}" \
            "ckan.datastore.read_url|${CKAN_DATASTORE_READ_URL}" \
            "solr_url|${CKAN_SOLR_URL}" \
            "ckan.redis.url|${CKAN_REDIS_URL}" \
            > "$REPLACE_FILE"
          # ADD_LINES content (one entry per line). Comments start with '#'
          cat > "$ADD_FILE" <<'EOF'
          ckan.site_id = default
          ckan.site_title = CKAN Test
          ckan.auth.create_default_api_keys = true
          ckanext.datapusher_plus.qsv_bin = /usr/local/bin/qsvdp
          scheming.dataset_schemas = ckanext.datapusher_plus:dataset-druf.yaml
          scheming.presets = ckanext.scheming:presets.json
          scheming.dataset_fallback = false
          ckanext.datapusher_plus.use_proxy = false
          ckanext.datapusher_plus.download_proxy = 
          ckanext.datapusher_plus.ssl_verify = false
          # supports INFO, DEBUG, TRACE - use DEBUG or TRACE when debugging scheming Formulas
          ckanext.datapusher_plus.upload_log_level = INFO
          ckanext.datapusher_plus.formats = csv tsv tab ssv xls xlsx xlsxb xlsm ods geojson shp qgis zip
          ckanext.datapusher_plus.pii_screening = false
          ckanext.datapusher_plus.pii_found_abort = false
          ckanext.datapusher_plus.pii_regex_resource_id_or_alias =
          ckanext.datapusher_plus.pii_show_candidates = false
          ckanext.datapusher_plus.pii_quick_screen = false
          ckanext.datapusher_plus.preview_rows = 100
          ckanext.datapusher_plus.download_timeout = 300
          ckanext.datapusher_plus.max_content_length = 1256000000000
          ckanext.datapusher_plus.chunk_size = 16384
          ckanext.datapusher_plus.default_excel_sheet = 0
          ckanext.datapusher_plus.sort_and_dupe_check = true
          ckanext.datapusher_plus.dedup = false
          ckanext.datapusher_plus.unsafe_prefix = unsafe_
          ckanext.datapusher_plus.reserved_colnames = _id
          ckanext.datapusher_plus.prefer_dmy = false
          ckanext.datapusher_plus.ignore_file_hash = true
          ckanext.datapusher_plus.auto_index_threshold = 3
          ckanext.datapusher_plus.auto_index_dates = true
          ckanext.datapusher_plus.auto_unique_index = true
          ckanext.datapusher_plus.summary_stats_options =
          ckanext.datapusher_plus.add_summary_stats_resource = false
          ckanext.datapusher_plus.summary_stats_with_preview = false
          ckanext.datapusher_plus.qsv_stats_string_max_length = 32767
          ckanext.datapusher_plus.qsv_dates_whitelist = date,time,due,open,close,created
          ckanext.datapusher_plus.qsv_freq_limit = 10
          ckanext.datapusher_plus.auto_alias = true
          ckanext.datapusher_plus.auto_alias_unique = false
          ckanext.datapusher_plus.copy_readbuffer_size = 1048576
          ckanext.datapusher_plus.type_mapping = {"String": "text", "Integer": "numeric","Float": "numeric","DateTime": "timestamp","Date": "date","NULL": "text"}
          ckanext.datapusher_plus.auto_spatial_simplication = true
          ckanext.datapusher_plus.spatial_simplication_relative_tolerance = 0.1
          ckanext.datapusher_plus.latitude_fields = latitude,lat
          ckanext.datapusher_plus.longitude_fields = longitude,long,lon
          ckanext.datapusher_plus.jinja2_bytecode_cache_dir = /tmp/jinja2_butecode_cache
          ckanext.datapusher_plus.auto_unzip_one_file = true
          EOF
          if [ -f /srv/app/src/ckan/test-core.ini ]; then
            echo "Patching selective keys in /srv/app/src/ckan/test-core.ini (only the keys you listed)..."
            # Ensure single debug = true under [DEFAULT]: remove existing debug lines in DEFAULT then add one
            awk 'BEGIN{in=0}
              /^\[DEFAULT\]/{ print; in=1; next }
              /^\[.*\]/{ if(in){ print "debug = true"; in=0 } }
              {
                if(in){
                  if($1 == "debug") next
                  print
                } else {
                  print
                }
              }
              END { if(in) print "debug = true" }' /srv/app/src/ckan/test-core.ini > /srv/app/src/ckan/test-core.ini.tmp && mv /srv/app/src/ckan/test-core.ini.tmp /srv/app/src/ckan/test-core.ini
            # Process REPLACE_FILE: replace if present, otherwise write to missing file
            while IFS= read -r entry || [ -n "$entry" ]; do
              key="$(printf '%s' "$entry" | cut -d'|' -f1)"
              value="$(printf '%s' "$entry" | cut -d'|' -f2-)"
              # escape backslashes and ampersands for sed replacement
              esc_value="$(printf '%s' "$value" | sed -e 's/[\/&]/\\&/g')"
              if grep -q -E "^[[:space:]]*$(printf '%s' "$key" | sed 's/[][^$.*/]/\\&/g')[[:space:]]*=" /srv/app/src/ckan/test-core.ini; then
                sed -i -E "s|^[[:space:]]*$(printf '%s' "$key" | sed 's/[][^$.*/]/\\&/g')[[:space:]]*=.*|${key} = ${esc_value}|g" /srv/app/src/ckan/test-core.ini  
              else
                printf '%s\n' "${key} = ${value}" >> "$MISSING_ADD_FILE"
              fi
            done < "$REPLACE_FILE"
            # Process ADD_FILE: replace if present, otherwise collect to missing file
            while IFS= read -r ln || [ -n "$ln" ]; do
              # comment lines - check if exact comment exists
              case "$ln" in
                \#*)
                  if ! grep -Fq "$ln" /srv/app/src/ckan/test-core.ini; then
                    printf '%s\n' "$ln" >> "$MISSING_ADD_FILE"
                  fi
                  ;;
                *)
                  key="$(printf '%s' "$ln" | cut -d'=' -f1 | sed 's/[[:space:]]*$//')"
                  value="$(printf '%s' "$ln" | cut -d'=' -f2- | sed 's/^[[:space:]]*//')"
                  esc_value="$(printf '%s' "$value" | sed -e 's/[\/&]/\\&/g')"
                  if grep -q -E "^[[:space:]]*$(printf '%s' "$key" | sed 's/[][^$.*/]/\\&/g')[[:space:]]*=" /srv/app/src/ckan/test-core.ini; then
                    sed -i -E "s|^[[:space:]]*$(printf '%s' "$key" | sed 's/[][^$.*/]/\\&/g')[[:space:]]*=.*|${key} = ${esc_value}|g" /srv/app/src/ckan/test-core.ini  
                  else
                    printf '%s\n' "${key} = ${value}" >> "$MISSING_ADD_FILE"
                  fi
                  ;;
              esac
            done < "$ADD_FILE"
            # If there are missing lines, insert them after the first [app:main] header, or append the section
            if [ -s "$MISSING_ADD_FILE" ]; then
              awk -v addfile="$MISSING_ADD_FILE" '
                BEGIN{
                  inserted=0
                  while ((getline line < addfile) > 0) { add[++na]=line }
                  close(addfile)
                }
                {
                  print
                  if(!inserted && $0=="[app:main]") {
                    for(i=1;i<=na;i++) print add[i]
                    inserted=1
                  }
                }
                END{
                  if(!inserted){
                    print "[app:main]"
                    for(i=1;i<=na;i++) print add[i]
                  }
                }' /srv/app/src/ckan/test-core.ini > /srv/app/src/ckan/test-core.ini.new && mv /srv/app/src/ckan/test-core.ini.new /srv/app/src/ckan/test-core.ini
            fi
            # Final defensive catch: ensure sqlalchemy and datastore URLs reflect env (again)
            sed -i "s|^sqlalchemy.url.*|sqlalchemy.url = ${CKAN_SQLALCHEMY_URL}|g" /srv/app/src/ckan/test-core.ini  
            sed -i "s|^ckan.datastore.write_url.*|ckan.datastore.write_url = ${CKAN_DATASTORE_WRITE_URL}|g" /srv/app/src/ckan/test-core.ini  
            sed -i "s|^ckan.datastore.read_url.*|ckan.datastore.read_url = ${CKAN_DATASTORE_READ_URL}|g" /srv/app/src/ckan/test-core.ini  
          else
            echo "/srv/app/src/ckan/test-core.ini not found — no selective patching performed."
          fi
          # Append datapusher plugin(s) to ckan.plugins if present; otherwise add a plugins line
          REQUIRED_PLUGINS="datastore datapusher_plus scheming_datasets"
          if grep -q "^ckan.plugins" /srv/app/src/ckan/test-core.ini; then
            echo "Appending required plugins to existing ckan.plugins line"
            current=$(grep "^ckan.plugins" /srv/app/src/ckan/test-core.ini | head -n1 | cut -d'=' -f2-)
            for p in $REQUIRED_PLUGINS; do
              echo "$current" | grep -qw "$p" || current="$current $p"
            done
            awk -v new="ckan.plugins = $current" 'BEGIN{done=0} {if(!done && $1=="ckan.plugins") {print new; done=1} else print $0}' /srv/app/src/ckan/test-core.ini > /srv/app/src/ckan/test-core.ini.new && mv /srv/app/src/ckan/test-core.ini.new /srv/app/src/ckan/test-core.ini
          else
            echo "ckan.plugins = $REQUIRED_PLUGINS" >> /srv/app/src/ckan/test-core.ini
            echo "Added ckan.plugins line with required plugins."
          fi
          echo "---- /srv/app/src/ckan/test-core.ini (cat) ----"
          cat /srv/app/src/ckan/test-core.ini  
          echo "---- end ----"
      - name: Initialize CKAN database
        run: |
          
          echo "Testing connectivity with CKAN DB user..."
          if ! PGPASSWORD=$CKAN_DB_PASSWORD psql -h postgres -U ckan_default -d ckan_test -c "SELECT 1;" >/dev/null 2>&1; then
            echo "Cannot connect as ckan_default. Attempting to create database owner and db..."
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE USER IF NOT EXISTS ckan_default WITH PASSWORD '$CKAN_DB_PASSWORD';"  
            PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres -c "CREATE DATABASE IF NOT EXISTS ckan_test OWNER ckan_default;"  
          fi
          echo "Running ckan db init (may be idempotent)..."
          if ckan -c /srv/app/src/ckan/test-core.ini db init; then
            echo "CKAN DB initialized."
          else
            echo "ckan db init returned non-zero; continuing (may already be initialized)."
          fi
          echo "Setting datastore permissions..."
          if ckan -c /srv/app/src/ckan/test-core.ini datastore set-permissions | PGPASSWORD=$POSTGRES_PASSWORD psql -h postgres -U postgres --set ON_ERROR_STOP=1; then
            echo "Datastore permissions set."
          else
            echo "Datastore permission step returned non-zero; continuing."
          fi
      - name: Start CKAN server
        run: |
          set -eu
          echo "Starting CKAN server in background..."
          # Use nohup to keep it running in background
          nohup ckan -c /srv/app/src/ckan/test-core.ini run --host 0.0.0.0 --port 5000 --disable-reloader > /tmp/ckan_stdout.log 2>&1 &
          CKAN_PID=$!
          echo "CKAN PID=$CKAN_PID"
          # wait for port / API
          timeout=120
          while [ $timeout -gt 0 ]; do
            if ! kill -0 "$CKAN_PID" >/dev/null 2>&1; then
              echo "CKAN process died. Showing last lines of log:"
              tail -n 200 /tmp/ckan_stdout.log  
              exit 1
            fi
            if curl -fsS "${CKAN_SITE_URL}/api/3/action/status_show" >/dev/null 2>&1; then
              echo "CKAN API responding"
              break
            fi
            echo "Waiting for CKAN API... ($timeout s left)"
            sleep 3
            timeout=$((timeout-3))
          done
          if [ $timeout -le 0 ]; then
            echo "Timeout waiting for CKAN to start. Dumping logs..."
            tail -n 200 /tmp/ckan_stdout.log  
            ss -tlnp || netstat -tlnp  
            exit 1
          fi
          echo "CKAN started successfully"
          
      - name: Create sysadmin user admin_ckan and get apikey
        run: |
          set -eu
          echo "Creating user admin_ckan..."
          
          user_response=$(ckanapi action user_create --config /srv/app/src/ckan/test-core.ini \
            name=admin_ckan \
            email=admins@example.com \
            password=test1234 \
            fullname="CKAN Administrator" \
            with_apitoken=true \
            about="Created by GitHub Actions test" 2>/dev/null) || echo "user_create returned non-zero (user may already exist)"
          
          echo "User creation response: $user_response"
          echo "Converting admin_ckan user to sysadmin..."
          ckan -c /srv/app/src/ckan/test-core.ini sysadmin add admin_ckan
          echo "User admin_ckan promoted to sysadmin"
          
          # Extract only the JSON part (everything from { to })
          json_response=$(echo "$user_response" | sed -n '/{/,/}/p')
          
          # Extract API key from the JSON
          api_key=$(echo "$json_response" | jq -r '.token // empty')
          
          if [ -n "$api_key" ] && [ "$api_key" != "null" ] && [ "$api_key" != "empty" ]; then
            echo "CKAN_API_KEY=$api_key" >> $GITHUB_ENV
            echo "API key saved: $api_key"
          else
            echo "No API key found in response"
          fi
          
          echo "User admin_ckan creation completed"
           
      - name: Create API token for datapusher-plus and add to config
        run: |
          set -eu
          echo "Creating API token for datapusher-plus service account..."
          
          # Create API token for admin_ckan user specifically for datapusher-plus
          echo "Running: ckan user token add admin_ckan dpplus"
          dp_token_output=$(ckan -c /srv/app/src/ckan/test-core.ini user token add admin_ckan dpplus 2>&1)
          echo "Full token creation output:"
          echo "$dp_token_output"
          
          dp_token=$(echo "$dp_token_output" | tail -n 1 | tr -d '\t')
          echo "Extracted token: '$dp_token'"
          
          if [ -n "$dp_token" ] && [ "$dp_token" != "null" ]; then
            echo "Created datapusher-plus API token: $dp_token"
            
            # Add the token to the CKAN configuration file
            ckan config-tool /srv/app/src/ckan/test-core.ini "ckanext.datapusher_plus.api_token=$dp_token"
            
            # Verify it was added
            echo "Verifying token was added to config:"
            grep "ckanext.datapusher_plus.api_token" /srv/app/src/ckan/test-core.ini || echo "Token not found in config!"
            
            # Also set in environment for potential use in other steps
            echo "DATAPUSHER_PLUS_API_TOKEN=$dp_token" >> $GITHUB_ENV
            
            echo "API token added to CKAN configuration successfully"
          else
            echo "Failed to create API token for datapusher-plus"
            echo "Using main CKAN API key as fallback..."
            ckan config-tool /srv/app/src/ckan/test-core.ini "ckanext.datapusher_plus.api_token=$CKAN_API_KEY"
          fi
      - name: Create organization with ckanapi
        run: |
          set -eu
          echo "Creating organization demo-organization (idempotent)..."
          ckanapi action organization_create --config /srv/app/src/ckan/test-core.ini \
            name=demo-organization \
            title="Demo Data Publishing Organization" \
            description="Demo org created by GitHub Actions for datapusher-plus testing." || echo "organization_create returned non-zero (may already exist)"
          echo "Add admin_ckan as admin to the organization"
          ckanapi action organization_member_create --config /srv/app/src/ckan/test-core.ini \
            id=demo-organization username=admin_ckan role=admin || echo "organization_member_create returned non-zero (may already be member)"
      
      - name: Create dataset with ckanapi
        run: |
          set -eu
          echo "Creating dataset my-first-dataset (idempotent)..."
          if ckanapi action package_create \
            name=my-first-dataset \
            title="My First Comprehensive Dataset" \
            notes="This is a comprehensive demo dataset created via ckanapi and GitHub Actions for testing CKAN functionality and datapusher-plus integration." \
            owner_org=demo-organization \
            license_id=cc-by \
            version=1.0.0 \
            author="GitHub Actions Automation" \
            author_email=noreply@example.com \
            maintainer="CKAN Admin" \
            maintainer_email=admin@example.com \
            url=https://github.com/your-repo/your-project \
            private:false \
            state=active \
            'tags:[{"name":"demo"},{"name":"test"},{"name":"github-actions"},{"name":"automation"},{"name":"csv-data"},{"name":"datapusher-plus"}]' \
            -c /srv/app/src/ckan/test-core.ini; then
            echo "Dataset created successfully!"
          else
            echo "Dataset might already exist, continuing..."
          fi
      - name: Add resource to dataset with ckanapi
        run: |
          set -eu
          echo "Adding resource to my-first-dataset..."
          if ckanapi action resource_create \
            package_id=my-first-dataset \
            url="https://raw.githubusercontent.com/frictionlessdata/test-data/master/files/csv/100kb.csv" \
            name="Sample CSV Data - 100KB Test File" \
            description="Test CSV resource for datapusher-plus pipeline." \
            format=CSV \
            mimetype="text/csv" \
            -c /srv/app/src/ckan/test-core.ini; then
            echo "Resource created successfully!"
          else
            echo "Resource creation failed"
            ckanapi action package_show id=my-first-dataset -c /srv/app/src/ckan/test-core.ini  
            exit 1
          fi
          
      - name: Display CKAN instance inventory
        run: |
          set -eu
          echo "=== CKAN Status (HTTP API) ==="
          curl -s "http://localhost:5000/api/3/action/status_show" | python3 -m json.tool  
          echo ""
          echo "=== All Datasets (HTTP API) ==="
          curl -s "http://localhost:5000/api/3/action/package_list" | python3 -m json.tool  
          echo ""
          echo "=== All Organizations (HTTP API) ==="
          curl -s "http://localhost:5000/api/3/action/organization_list" | python3 -m json.tool  
          echo ""
          echo "=== All Users (HTTP API) ==="
          curl -s "http://localhost:5000/api/3/action/user_list" | python3 -m json.tool  
      - name: Test datastore functionality
        run: |
          set -eu
          echo "Testing datastore functionality..."
          
          # Test 1: Check if datastore is accessible by querying table metadata
          echo "=== Testing datastore read access ==="
          metadata_response=$(curl -s "http://localhost:5000/api/3/action/datastore_search?resource_id=_table_metadata")
          echo "Table metadata response: $metadata_response"
          
          if echo "$metadata_response" | jq -e '.success == true' >/dev/null 2>&1; then
            echo "✓ Datastore read access working"
          else
            echo "✗ Datastore read access failed"
            exit 1
          fi
          
          # Test 2: Create a test datastore table
          echo "=== Testing datastore write access ==="
          test_response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: $CKAN_API_KEY" \
            -d '{
              "resource": {"package_id": "my-first-dataset"},
              "fields": [{"id": "test_col", "type": "text"}, {"id": "value", "type": "int"}],
              "records": [{"test_col": "hello", "value": 1}, {"test_col": "world", "value": 2}]
            }' \
            "http://localhost:5000/api/3/action/datastore_create")
          
          echo "Test table creation response: $test_response"
          
          if echo "$test_response" | jq -e '.success == true' >/dev/null 2>&1; then
            echo "✓ Datastore write access working"
            
            # Extract resource_id for cleanup
            test_resource_id=$(echo "$test_response" | jq -r '.result.resource_id')
            
            # Test 3: Query the test table
            echo "=== Testing datastore query ==="
            query_response=$(curl -s "http://localhost:5000/api/3/action/datastore_search?resource_id=$test_resource_id")
            echo "Query response: $query_response"
            
            # Cleanup: Delete test table
            echo "=== Cleaning up test table ==="
            curl -s -X POST \
              -H "Content-Type: application/json" \
              -H "Authorization: $CKAN_API_KEY" \
              -d "{\"resource_id\": \"$test_resource_id\"}" \
              "http://localhost:5000/api/3/action/datastore_delete" >/dev/null
            
            echo "✓ Datastore functionality test completed successfully"
          else
            echo "✗ Datastore write access failed"
          fi
      - name: Start CKAN background job worker
        run: |
          set -eu
          echo "Starting CKAN background job worker (CRITICAL for DataPusher Plus)..."
          nohup ckan -c /srv/app/src/ckan/test-core.ini jobs worker > /tmp/ckan_worker.log 2>&1 &
          WORKER_PID=$!
          echo "CKAN Worker PID=$WORKER_PID"
          echo "CKAN_WORKER_PID=$WORKER_PID" >> $GITHUB_ENV
          
          # Give worker a moment to start up
          sleep 5
          
          # Verify worker is running
          if kill -0 "$WORKER_PID" >/dev/null 2>&1; then
            echo "Background job worker started successfully"
            echo "Worker logs:"
            head -n 20 /tmp/ckan_worker.log || echo "No worker logs yet"
          else
            echo "Worker failed to start"
            cat /tmp/ckan_worker.log
            exit 1
          fi
      - name: Test DataPusher Plus functionality with multiple files
        run: |
          set -eu
          echo "=== Testing DataPusher Plus with Multiple Files ==="
          
          # Initialize results tracking
          echo "file_name,file_url,upload_status,resource_id,datapusher_status,datastore_active,rows_imported,processing_time,error_message" > /tmp/test_results.csv
          
          # Define test files array (URL and description pairs)
          declare -A test_files
          test_files["small_valid.csv"]="https://raw.githubusercontent.com/a5dur/datapusher-plus/refs/heads/main/tests/static/small_valid.csv|Small CSV with basic employee data"
          test_files["medium_mixed_types.csv"]="https://raw.githubusercontent.com/a5dur/datapusher-plus/refs/heads/main/tests/static/medium_mixed_types.csv|Medium CSV with mixed data types"
          test_files["unicode_special.csv"]="https://raw.githubusercontent.com/a5dur/datapusher-plus/refs/heads/main/tests/static/unicode_special.csv|CSV with Unicode and special characters"
   
          # Create test dataset once
          echo "Creating test dataset for DataPusher Plus..."
          if ckanapi action package_create \
            name=datapusher-plus-multi-test \
            title="DataPusher Plus Multi-File Test Dataset" \
            owner_org=demo-organization \
            -c /srv/app/src/ckan/test-core.ini >/dev/null 2>&1; then
            echo "Test dataset created"
          else
            echo "Test dataset might already exist, continuing..."
          fi
          
          # Counters for summary
          total_files=0
          passed_files=0
          failed_files=0
          
          # Test each file
          for file_name in "${!test_files[@]}"; do
            total_files=$((total_files + 1))
            IFS='|' read -r file_url description <<< "${test_files[$file_name]}"
            
            echo ""
            echo "============================================="
            echo "Testing File $total_files: $file_name"
            echo "Description: $description"
            echo "URL: $file_url"
            echo "============================================="
            
            start_time=$(date +%s)
            upload_status="FAILED"
            resource_id=""
            datapusher_status="N/A"
            datastore_active="false"
            rows_imported="0"
            error_message=""
            
            # Create resource for this file
            echo "Creating resource for $file_name..."
            if resource_response=$(ckanapi action resource_create \
              package_id=datapusher-plus-multi-test \
              url="$file_url" \
              name="Test: $file_name" \
              description="$description" \
              format=CSV \
              mimetype="text/csv" \
              -c /srv/app/src/ckan/test-core.ini 2>&1); then
              
              echo "Resource created successfully!"
              upload_status="SUCCESS"
              
              # Extract resource ID (using corrected extraction)
              resource_id=$(echo "$resource_response" | grep -o '"id"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"id"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/')
              
              if [ -z "$resource_id" ]; then
                resource_id=$(echo "$resource_response" | sed -n 's/.*"id"[[:space:]]*:[[:space:]]*"\([a-f0-9-]*\)".*/\1/p' | head -1)
              fi
              
              echo "Resource ID: $resource_id"
              
              if [ -n "$resource_id" ] && [ "$resource_id" != "null" ]; then
                # Monitor DataPusher Plus processing (shorter timeout per file)
                echo "Monitoring DataPusher Plus processing..."
                for attempt in $(seq 1 30); do
                  sleep 2
                  
                  if dp_status_response=$(curl -s -H "Authorization: $CKAN_API_KEY" \
                    "http://localhost:5000/api/3/action/datapusher_status?resource_id=$resource_id"); then
                    
                    if echo "$dp_status_response" | grep -q '"success"[[:space:]]*:[[:space:]]*true'; then
                      # Extract status and clean it
                      datapusher_status=$(echo "$dp_status_response" | grep -o '"status"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"status"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/' | cut -c1-8 | tr -d '\n\r\t ')
                      
                      if [ -z "$datapusher_status" ]; then
                        datapusher_status="unknown"
                      fi
                      
                      echo "Attempt $attempt: DataPusher status = $datapusher_status"
                      
                      if [ "$datapusher_status" = "complete" ]; then
                        echo "DataPusher processing completed for $file_name!"
                        break
                      elif [ "$datapusher_status" = "error" ]; then
                        error_info=$(echo "$dp_status_response" | grep -o '"message"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"message"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/')
                        if [ -z "$error_info" ]; then
                          error_info="DataPusher processing error"
                        fi
                        error_message="DataPusher error: $error_info"
                        echo "DataPusher processing failed for $file_name: $error_message"
                        break
                      fi
                    else
                      echo "DataPusher status API error"
                      error_message="DataPusher status API error"
                      break
                    fi
                  else
                    echo "Failed to get DataPusher status"
                    break
                  fi
                  
                  # Show progress less frequently for multiple files
                  if [ $((attempt % 15)) -eq 0 ]; then
                    echo "Still processing $file_name... (${attempt}/30)"
                  fi
                done
                
                # Check final status
                echo "Checking final status for $file_name..."
                if final_resource=$(curl -s "http://localhost:5000/api/3/action/resource_show?id=$resource_id"); then
                  if echo "$final_resource" | grep -q '"datastore_active"[[:space:]]*:[[:space:]]*true'; then
                    datastore_active="true"
                    
                    if datastore_data=$(curl -s "http://localhost:5000/api/3/action/datastore_search?resource_id=$resource_id&limit=1"); then
                      if echo "$datastore_data" | grep -q '"total"'; then
                        rows_imported=$(echo "$datastore_data" | grep -o '"total"[[:space:]]*:[[:space:]]*[0-9]*' | head -1 | sed 's/.*"total"[[:space:]]*:[[:space:]]*\([0-9]*\).*/\1/')
                        if [ -z "$rows_imported" ]; then
                          rows_imported="0"
                        fi
                      fi
                    fi
                  else
                    datastore_active="false"
                  fi
                fi
              else
                error_message="No valid resource ID extracted"
              fi
            else
              echo "Resource creation failed for $file_name"
              error_message="Resource creation failed"
            fi
            
            end_time=$(date +%s)
            processing_time=$((end_time - start_time))
            
            # Determine result for this file
            if [ "$upload_status" = "SUCCESS" ] && [ "$datapusher_status" = "complete" ] && [ "$datastore_active" = "true" ]; then
              file_result="PASS"
              passed_files=$((passed_files + 1))
              echo "✅ PASS: $file_name (${rows_imported} rows imported in ${processing_time}s)"
            else
              file_result="FAIL"
              failed_files=$((failed_files + 1))
              echo "❌ FAIL: $file_name ($error_message)"
            fi
            
            # Log results
            echo "$file_name,$file_url,$upload_status,$resource_id,$datapusher_status,$datastore_active,$rows_imported,$processing_time,\"$error_message\"" >> /tmp/test_results.csv
          done
          
          # Final summary
          echo ""
          echo "============================================="
          echo "=== FINAL TEST SUMMARY ==="
          echo "============================================="
          echo "Total files tested: $total_files"
          echo "Passed: $passed_files"
          echo "Failed: $failed_files"
          echo ""
          
          if [ $passed_files -eq $total_files ]; then
            echo "🎉 OVERALL RESULT: ALL TESTS PASSED"
            echo "DataPusher Plus is working correctly for all file types!"
          elif [ $passed_files -gt 0 ]; then
            echo "⚠️  OVERALL RESULT: PARTIAL SUCCESS"
            echo "Some files passed, some failed. Check individual results."
          else
            echo "❌ OVERALL RESULT: ALL TESTS FAILED"
            echo "DataPusher Plus has significant issues."
          fi

      - name: Generate comprehensive multi-file test report
        run: |
          set -eu
          echo "=== DataPusher Plus Multi-File Test Report ==="
          
          if [ -f /tmp/test_results.csv ]; then
            echo ""
            echo "| File Name | Status | Rows | Time (s) | DataStore | Error |"
            echo "|-----------|--------|------|----------|-----------|-------|"
            
            # Process each result line
            tail -n +2 /tmp/test_results.csv | while IFS=',' read -r file_name file_url upload_status resource_id datapusher_status datastore_active rows_imported processing_time error_message; do
              # Clean up fields
              file_name=$(echo "$file_name" | tr -d '"')
              datapusher_status=$(echo "$datapusher_status" | tr -d '"')
              datastore_active=$(echo "$datastore_active" | tr -d '"')
              rows_imported=$(echo "$rows_imported" | tr -d '"')
              processing_time=$(echo "$processing_time" | tr -d '"')
              error_message=$(echo "$error_message" | tr -d '"' | cut -c1-30)
              
              # Determine overall status
              if [ "$upload_status" = "SUCCESS" ] && [ "$datapusher_status" = "complete" ] && [ "$datastore_active" = "true" ]; then
                overall_status="✅ PASS"
              else
                overall_status="❌ FAIL"
              fi
              
              echo "| $file_name | $overall_status | $rows_imported | $processing_time | $datastore_active | $error_message |"
            done
            
            echo ""
            echo "Raw results saved to artifact: test_results.csv"
          else
            echo "No test results file found"
          fi
      - name: Upload multi-file test results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: datapusher-plus-multi-file-test-results
          path: |
            /tmp/test_results.csv
            /tmp/ckan_stdout.log
            /tmp/ckan_worker.log
          retention-days: 3
      - name: Cleanup
        if: always()
        run: |
          echo "Stopping any running CKAN processes..."
          pkill -f "ckan.*run"  
          echo "Cleanup completed"
          
